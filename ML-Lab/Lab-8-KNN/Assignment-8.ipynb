{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55547867",
   "metadata": {},
   "source": [
    "# Q1) K-Nearest Neighbors (KNN) Classifier and Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d2cca",
   "metadata": {},
   "source": [
    "### a) Load the Iris dataset, split it into training and testing sets, and implement a K-Nearest Neighbors Classifier to predict the flower species. Evaluate the model performance using accuracy and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6c3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",header=None,\n",
    "               names=['sepal_length','sepal_width','petal_length','petal_width','species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b15e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop('species',axis=1)\n",
    "y=df['species']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94da20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n",
      "Confusion Matrix is :\n",
      " [[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "k=KNeighborsClassifier()\n",
    "k.fit(X_train,y_train)\n",
    "y_pred=k.predict(X_test)\n",
    "print(f\"Accuracy is {accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"Confusion Matrix is :\\n {confusion_matrix(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14c217",
   "metadata": {},
   "source": [
    "### b) Experiment with different values of k (e.g., 3, 5, 7, 9) and plot how accuracy changes with k. Briefly explain the effect of k on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "510880b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=KNeighborsClassifier(n_neighbors=3)\n",
    "k1.fit(X_train,y_train)\n",
    "y_pred=k1.predict(X_test)\n",
    "accu1=accuracy_score(y_test,y_pred)\n",
    "\n",
    "k2=KNeighborsClassifier(n_neighbors=5)\n",
    "k2.fit(X_train,y_train)\n",
    "y_pred=k2.predict(X_test)\n",
    "accu2=accuracy_score(y_test,y_pred)\n",
    "\n",
    "k3=KNeighborsClassifier(n_neighbors=7)\n",
    "k3.fit(X_train,y_train)\n",
    "y_pred=k3.predict(X_test)\n",
    "accu3=accuracy_score(y_test,y_pred)\n",
    "\n",
    "k4=KNeighborsClassifier(n_neighbors=9)\n",
    "k4.fit(X_train,y_train)\n",
    "y_pred=k4.predict(X_test)\n",
    "accu4=accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfd04c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "x=[3,5,7,9]\n",
    "y=[accu1,accu2,accu3,accu4]\n",
    "pl.xlabel(\"Value of K\")\n",
    "pl.ylabel(\"Accuray\")\n",
    "pl.xticks(x)\n",
    "pl.bar(x,y)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d32a4",
   "metadata": {},
   "source": [
    "### c) Using the California Housing Dataset, implement a KNeighborsRegressor to predict median house prices. Evaluate the model using RMSE and RÂ² score, and discuss the impact of n_neighbors on regression performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d694b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 1.0640592412378382\n",
      "R2 score is 0.14434206676911643\n",
      "RMSE is 1.0916672624057806\n",
      "R2 score is 0.09936433957213608\n",
      "RMSE is 1.0576176259351788\n",
      "R2 score is 0.15467069371590192\n",
      "RMSE is 1.060059975888558\n",
      "R2 score is 0.15076195805631398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import root_mean_squared_error,r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "X,y=fetch_california_housing(return_X_y=True)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,shuffle=True)\n",
    "r=KNeighborsRegressor()\n",
    "r.fit(X_train,y_train)\n",
    "y_pred=r.predict(X_test)\n",
    "print(f\"RMSE is {root_mean_squared_error(y_test,y_pred)}\")\n",
    "print(f\"R2 score is {r2_score(y_test,y_pred)}\")\n",
    "\n",
    "r1=KNeighborsRegressor(n_neighbors=3)\n",
    "r1.fit(X_train,y_train)\n",
    "y_pred=r1.predict(X_test)\n",
    "print(f\"RMSE is {root_mean_squared_error(y_test,y_pred)}\")\n",
    "print(f\"R2 score is {r2_score(y_test,y_pred)}\")\n",
    "\n",
    "r2=KNeighborsRegressor(n_neighbors=7)\n",
    "r2.fit(X_train,y_train)\n",
    "y_pred=r2.predict(X_test)\n",
    "print(f\"RMSE is {root_mean_squared_error(y_test,y_pred)}\")\n",
    "print(f\"R2 score is {r2_score(y_test,y_pred)}\")\n",
    "\n",
    "r3=KNeighborsRegressor(n_neighbors=9)\n",
    "r3.fit(X_train,y_train)\n",
    "y_pred=r3.predict(X_test)\n",
    "print(f\"RMSE is {root_mean_squared_error(y_test,y_pred)}\")\n",
    "print(f\"R2 score is {r2_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95d309",
   "metadata": {},
   "source": [
    "# Q2) Naive Bayes with Mixed Numeric and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "478ace4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder,LabelBinarizer,KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060bf66",
   "metadata": {},
   "source": [
    "### a) Load and preprocess the dataset by handling missing values, encoding categorical variables (e.g., using OneHotEncoder), and scaling numeric variables (using StandardScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0e80a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "cols = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \"marital_status\",\"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "         \"capital_gain\", \"capital_loss\",\"hours_per_week\", \"native_country\", \"income\"]\n",
    "\n",
    "df = pd.read_csv(url, names=cols, na_values=\" ?\", skipinitialspace=True)\n",
    "\n",
    "X = df.drop(\"income\", axis=1)\n",
    "y = LabelBinarizer().fit_transform(df[\"income\"])\n",
    "\n",
    "numeric_features = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "categorical_features = [col for col in X.columns if col not in numeric_features]\n",
    "\n",
    "numeric_transformer_gnb = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_gnb = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\",sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor_gnb = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer_gnb, numeric_features),\n",
    "    (\"cat\", categorical_transformer_gnb, categorical_features)\n",
    "])\n",
    "\n",
    "numeric_transformer_cnb = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"discretizer\", KBinsDiscretizer(n_bins=20, encode='ordinal', strategy='quantile'))\n",
    "])\n",
    "\n",
    "categorical_transformer_cnb = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "])\n",
    "\n",
    "preprocessor_cnb = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer_cnb, numeric_features),\n",
    "    (\"cat\", categorical_transformer_cnb, categorical_features)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2f32c7",
   "metadata": {},
   "source": [
    "### b) Train two Naive Bayes models: GaussianNB and CategoricalNB. Compare their performance using accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e4d77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GaussianNB ===\n",
      "Accuracy: 0.4973897021189477\n",
      "Precision: 0.31945228684359117\n",
      "Recall: 0.9621598639455783\n",
      "\n",
      "=== CategoricalNB ===\n",
      "Accuracy: 0.8227044733340158\n",
      "Precision: 0.6007147498375569\n",
      "Recall: 0.7861394557823129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:296: FutureWarning: The current default behavior, quantile_method='linear', will be changed to quantile_method='averaged_inverted_cdf' in scikit-learn version 1.9 to naturally support sample weight equivalence properties by default. Pass quantile_method='averaged_inverted_cdf' explicitly to silence this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:397: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:397: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:397: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:397: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "c:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "pipe_gnb = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_gnb),\n",
    "    (\"classifier\", GaussianNB())\n",
    "])\n",
    "\n",
    "pipe_gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = pipe_gnb.predict(X_test)\n",
    "\n",
    "\n",
    "pipe_cnb = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_cnb),\n",
    "    (\"classifier\", CategoricalNB())\n",
    "])\n",
    "\n",
    "pipe_cnb.fit(X_train, y_train)\n",
    "y_pred_cnb = pipe_cnb.predict(X_test)\n",
    "\n",
    "\n",
    "def evaluate(name, y_true, y_pred):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "\n",
    "evaluate(\"GaussianNB\", y_test, y_pred_gnb)\n",
    "evaluate(\"CategoricalNB\", y_test, y_pred_cnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d87ba",
   "metadata": {},
   "source": [
    "### c) Analyze and explain which model performs better and why, considering the nature of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8806274",
   "metadata": {},
   "source": [
    "#### Accuracy of CategoricalNB is Higher than GaussianNB the nature of dataset allows continous features to be binned to classes efficiently\n",
    "#### Precision of CategoricalNB is higher meaning it deals better with False Positives\n",
    "#### Recall of GaussianNB is higher meaning it deals better with False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca9b23",
   "metadata": {},
   "source": [
    "# Q3) Multinomial Naive Bayes for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e742648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2ab7f",
   "metadata": {},
   "source": [
    "### a) Load the training and test data from the 20 Newsgroups dataset. Preprocess the text using TfidfVectorizer or CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbdc7f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "test_data = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae0b678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_df=0.7)\n",
    "X_train = vectorizer.fit_transform(train_data.data)\n",
    "X_test = vectorizer.transform(test_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ad117",
   "metadata": {},
   "source": [
    "### b) Train a Multinomial Naive Bayes classifier to predict the newsgroup category of each document. Evaluate the model using accuracy, precision, recall, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8d056f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, train_data.target)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d08c907c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6343600637280935\n",
      "Precision: 0.6485354513688819\n",
      "Recall: 0.6185519602342504\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 97   1   0   1   0   3   0   1   2   1  12   8   0   4  11 130   5  26\n",
      "   11   6]\n",
      " [  1 269   0  14   7  35   2   0   0   2   7  26   3   5   7   6   0   3\n",
      "    2   0]\n",
      " [  3  66   2 106  12 131   2   2   1   0  15  32   1   4   4   3   0   2\n",
      "    7   1]\n",
      " [  0  13   0 281  24  20   6   0   0   0   7  18  16   1   1   1   1   2\n",
      "    1   0]\n",
      " [  1  20   1  47 216  18   9   3   1   0  15  19  13   8   8   2   0   2\n",
      "    2   0]\n",
      " [  0  32   1   6   4 318   1   0   0   0   8  11   1   2   6   3   0   1\n",
      "    1   0]\n",
      " [  0   5   0  38  16   4 268   6   2   2  10   4   8   1  10   5   3   5\n",
      "    3   0]\n",
      " [  0   2   0   2   1   3   9 278  10   1  29   5   7   2  10   8  11   8\n",
      "   10   0]\n",
      " [  2   2   0   1   1   2   5  26 245   4  15  10  13   2   3  15  14  19\n",
      "   19   0]\n",
      " [  0   3   0   2   0   6   2   0   2 294  34   7   1   5   3  16   2   5\n",
      "   15   0]\n",
      " [  1   1   0   1   0   1   0   1   0   2 362   5   0   1   2   8   1   8\n",
      "    5   0]\n",
      " [  0   6   0   2   4   3   0   1   0   1  18 311   4   2   8   4  12  14\n",
      "    6   0]\n",
      " [  1  19   1  24   8  11   7   9   3   1  13  63 191  12  15   6   3   5\n",
      "    1   0]\n",
      " [  4   6   0   1   0   1   0   5   0   1  15   3   3 312   5  17   4   9\n",
      "   10   0]\n",
      " [  0  11   0   1   0   2   0   3   1   0  17  11   3   7 296  10   1  12\n",
      "   19   0]\n",
      " [  3   4   0   0   0   2   0   0   0   1  15   2   0   1   3 362   2   2\n",
      "    1   0]\n",
      " [  2   0   0   0   0   2   2   0   0   1  12  16   2   4   5  25 222  45\n",
      "   23   3]\n",
      " [  2   0   0   2   0   2   0   0   1   1   6   8   0   1   0  23   9 302\n",
      "   19   0]\n",
      " [  9   0   0   0   0   1   1   1   1   0   8  12   2   5   9  14  77  31\n",
      "  137   2]\n",
      " [ 23   0   0   2   0   2   0   1   0   1   8   4   1   4   7 132  25  18\n",
      "    8  15]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_data.target, y_pred)\n",
    "precision = precision_score(test_data.target, y_pred, average='macro')\n",
    "recall = recall_score(test_data.target, y_pred, average='macro')\n",
    "conf_matrix = confusion_matrix(test_data.target, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29bef8",
   "metadata": {},
   "source": [
    "### c) Display the top 10 most informative words for any two categories, and explain why Multinomial Naive Bayes works effectively for text-based data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49bb09ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 words for category 'rec.sport.hockey':\n",
      "['team' 'game' '10' 'hockey' '25' 'play' '55' 'season' '11' '12']\n",
      "\n",
      "Top 10 words for category 'sci.med':\n",
      "['edu' 'don' 'people' 'health' 'use' 'medical' 'like' 'know' 'com' 'time']\n"
     ]
    }
   ],
   "source": [
    "def show_top_informative_words(class_index, top_n=10):\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    class_log_prob = model.feature_log_prob_[class_index]\n",
    "    top_indices = np.argsort(class_log_prob)[::-1][:top_n]\n",
    "    top_words = feature_names[top_indices]\n",
    "    print(f\"\\nTop {top_n} words for category '{train_data.target_names[class_index]}':\")\n",
    "    print(top_words)\n",
    "\n",
    "cat1 = train_data.target_names.index('rec.sport.hockey')\n",
    "cat2 = train_data.target_names.index('sci.med')\n",
    "\n",
    "show_top_informative_words(cat1)\n",
    "show_top_informative_words(cat2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
